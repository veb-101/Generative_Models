{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:03:37.057499Z",
     "start_time": "2020-12-15T16:03:23.049064Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:03:39.526147Z",
     "start_time": "2020-12-15T16:03:37.089984Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:09:19.193827Z",
     "start_time": "2020-12-15T17:09:19.190866Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dims = 10\n",
    "num_epochs = 100\n",
    "variational_beta = 1\n",
    "batch_size = 128\n",
    "capacity = 64\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:09:22.538416Z",
     "start_time": "2020-12-15T17:09:22.491422Z"
    }
   },
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = MNIST(root='data/', train=True, \n",
    "                transform=img_transforms, download=True)\n",
    "\n",
    "# Training validation & test dataset\n",
    "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
    "\n",
    "# test_ds = MNIST(root='data/', train=False, \n",
    "#                 transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T09:01:42.210815Z",
     "start_time": "2020-12-15T09:01:42.201442Z"
    }
   },
   "source": [
    "# Move Data and model to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:09:22.845551Z",
     "start_time": "2020-12-15T17:09:22.842550Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else: \n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:09:23.011158Z",
     "start_time": "2020-12-15T17:09:22.992175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:09:23.161428Z",
     "start_time": "2020-12-15T17:09:23.156426Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:09:23.601480Z",
     "start_time": "2020-12-15T17:09:23.310510Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:09:23.718480Z",
     "start_time": "2020-12-15T17:09:23.609484Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:11:23.534121Z",
     "start_time": "2020-12-15T17:11:23.515924Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        c = capacity\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=c, kernel_size=4, stride=2, padding=1) # c*14*14\n",
    "        self.conv2 = nn.Conv2d(in_channels=c, out_channels=c*2, kernel_size=4, stride=2, padding=1) # c*7*7\n",
    "        self.fc_mu = nn.Linear(in_features=c*2*7*7, out_features=latend_dims)\n",
    "        self.fc_logvar = nn.Linear(in_features=c*2*7*7, out_features=latend_dims)\n",
    "\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = self.conv1(xb)\n",
    "        xb = F.relu(xb)\n",
    "        xb = self.conv2(xb)\n",
    "        xb = F.relu(xb)\n",
    "        xb = xb.view(xb.size(0), -1)\n",
    "        x_mu = self.fc_mu(xb)\n",
    "        x_logvar = self.fc_logvar(xb)\n",
    "        return x_mu, x_logvar\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        c = capacity\n",
    "        self.fc = nn.Linear(in_features=latent_dims, out_features=c*2*7*7)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=c*2, out_channels=c, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels=c, out_channels=1, kernel_size=4, stride=2, padding=1)\n",
    "            \n",
    "    def forward(self, xb):\n",
    "        xb = self.fc(xb)\n",
    "        xb = xb.view(xb.size(0), capacity*2, 7, 7)\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = torch.sigmoid(self.conv1(xb))\n",
    "        return xb\n",
    "    \n",
    "\n",
    "    \n",
    "def vae_loss(reconstruct, og, mu, logvar):\n",
    "    reconstruction_loss = F.binary_cross_entropy(reconstruct.view(-1, 784), og.view(-1, 784), reduction='sum')\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - torch.pow(mu, 2) - torch.exp(logvar))\n",
    "    return reconstruction_loss + variational_beta * kl_divergence\n",
    "    \n",
    "\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    def latent_sample(self, mu, logvar):\n",
    "        sigma = torch.exp(torch.mul(logvar, 0.5))\n",
    "        eps = torch.randn_like(sigma)\n",
    "        sample = mu + (sigma * eps)\n",
    "        return sample\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        latent_mu, latent_std = self.encoder(xb)\n",
    "        latent_ = self.latent_sample(latent_mu, latent_std)\n",
    "        reconstruction = self.decoder(latent_)\n",
    "        return reconstruction, latent_mu, latent_std\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        input_batch, _ = batch\n",
    "        input_batch_reconstruct, batch_mu, batch_std = self(input_batch)\n",
    "        loss = vae_loss(input_batch_reconstruct, input_batch, batch_mu, batch_std)\n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "    def valid_step(self, batch):\n",
    "        with torch.no_grad():\n",
    "            val_batch, _ = batch\n",
    "            val_batch_reconstruct, batch_mu, batch_std = self(val_batch)\n",
    "            loss = vae_loss(val_batch_reconstruct, val_batch, batch_mu, batch_std)\n",
    "            \n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def get_metrics_epoch_end(self, outputs, validation=True):\n",
    "        if validation:\n",
    "            loss_ = 'val_loss'\n",
    "        else:\n",
    "            loss_ = 'loss'\n",
    "            \n",
    "        batch_losses = [x[f'{loss_}'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        return {f'{loss_}': epoch_loss.item()}\n",
    "\n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        if (epoch+1) % 5 == 0 or epoch == num_epochs-1:\n",
    "            print(f\"Epoch [{epoch+1}] -> loss: {result['loss']:.4f}, val_loss: {result['val_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:11:23.829703Z",
     "start_time": "2020-12-15T17:11:23.819661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoEncoder(\n",
      "  (encoder): Encoder(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (fc_mu): Linear(in_features=6272, out_features=10, bias=True)\n",
      "    (fc_logvar): Linear(in_features=6272, out_features=10, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc): Linear(in_features=10, out_features=6272, bias=True)\n",
      "    (conv2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv1): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Number of parameters: 458901\n"
     ]
    }
   ],
   "source": [
    "model = VariationalAutoEncoder()\n",
    "to_device(model, device)\n",
    "print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Number of parameters: %d' % num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:11:24.052334Z",
     "start_time": "2020-12-15T17:11:24.047376Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.valid_step(batch) for batch in val_loader]\n",
    "    return model.get_metrics_epoch_end(outputs, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:16:40.458663Z",
     "start_time": "2020-12-15T17:16:40.451666Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=None):\n",
    "    history = []\n",
    "    \n",
    "    if not opt_func:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "    else:\n",
    "        optimizer = opt_func\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        train_history = []\n",
    "        model.train()\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            info = model.train_step(batch)\n",
    "            loss = info['loss']\n",
    "        \n",
    "            # contains batch loss for training phase\n",
    "            train_history.append(info)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        train_result = model.get_metrics_epoch_end(train_history, validation=False)\n",
    "        val_result = evaluate(model, val_loader)\n",
    "        result = {**train_result, **val_result}\n",
    "\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:16:47.576889Z",
     "start_time": "2020-12-15T17:16:40.911752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 122643.7734375}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [evaluate(model, val_loader)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T17:16:47.588887Z",
     "start_time": "2020-12-15T17:16:47.584884Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-15T17:16:43.310Z"
    }
   },
   "outputs": [],
   "source": [
    "history = fit(10, learning_rate, model, train_loader, val_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensortorch]",
   "language": "python",
   "name": "conda-env-tensortorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
